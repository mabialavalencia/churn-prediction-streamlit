#!/usr/bin/env python
# coding: utf-8

# # I.Contexte et Objectif

# Pr√©dire le d√©part des clients d'une banque √† partir de leurs donn√©es personnelles et comportementales. Ce mod√®le permettra √† la banque d‚Äôanticiper les risques d‚Äôattrition et de cibler les actions de fid√©lisation.

# # II. Probl√©matique

# - Quels facteurs influencent le d√©part des clients ?
# 
# - Peut-on pr√©dire √† l‚Äôavance si un client va quitter la banque ?
# 
# 

# # III. Analyse exploratoire (EDA)

# In[1]:


#import fichier

import pandas as pd 

df = pd.read_csv("C:\\Users\\Valencia\\Downloads\\Churn_Modelling (1).csv")

#aper√ßu des 5 premi√®res lignes 

df.head()


# In[2]:


# Dimensions du jeu de donn√©es
print(f"Nombre de lignes : {df.shape[0]}")
print(f"Nombre de colonnes : {df.shape[1]}")
 


# In[3]:


# Types de donn√©es et valeurs manquantes
df.info()


# Conclusion : Aucune valeur manquante dans mon Dataset

# In[4]:


df = df.drop(columns=["RowNumber", "CustomerId", "Surname"])


# In[5]:


# Analyse de la variable cible 

import seaborn as sns
import matplotlib.pyplot as plt

# R√©partition de la variable cible
sns.countplot(x="Exited", data=df)
plt.title("R√©partition des clients quittant la banque (Exited)")
plt.xlabel("Exited (0 = reste, 1 = quitte)")
plt.ylabel("Nombre de clients")
plt.show()


# In[6]:


# Pourcentage de churn
churn_rate = df['Exited'].mean()
print(f"Taux de churn : {churn_rate:.2%}")


#  Le taux de churn de 20,37% signifie que 20,37% des clients du dataset ont quitt√© la banque, ce qui est une information cl√© dans un projet de classification sur le churn

# üìä Interpr√©tation
# Sur 10 000 clients, environ 2 037 ont quitt√© la banque (Exited = 1).
# 
# Les 79,63% restants, soit environ 7 963 clients, sont rest√©s (Exited = 0).
# 
# Il s‚Äôagit d‚Äôun probl√®me de classification binaire d√©s√©quilibr√©, mais pas fortement (en g√©n√©ral, un d√©s√©quilibre commence √† poser probl√®me en dessous de 10‚Äì15%).

# # Analyse univari√©e + bivari√©e (relation avec Exited)
# 

# In[7]:


# Distribution de l'√¢ge selon le churn
plt.figure(figsize=(10, 5))
sns.histplot(data=df, x='Age', hue='Exited', bins=30, kde=True, multiple="stack")
plt.title("R√©partition de l'√¢ge selon le churn")
plt.xlabel("√Çge")
plt.ylabel("Nombre de clients")
plt.show()


# üìä 1. Age vs Exited
# Observation :
# 
# Les clients entre 30 et 40 ans sont majoritaires.
# 
# Le taux de churn augmente significativement avec l‚Äô√¢ge, notamment apr√®s 45 ans.
# 
# Les plus jeunes clients partent peu.
# 
# Interpr√©tation :
# 
# L‚Äô√¢ge est un facteur discriminant fort.
# 
# Les clients plus √¢g√©s sont peut-√™tre plus exigeants ou plus susceptibles de quitter la banque.
# 
# *** Pertinent √† garder pour la mod√©lisation.
# 
# 

# In[8]:


# R√©partition des sexes par churn
plt.figure(figsize=(6, 4))
sns.countplot(data=df, x='Gender', hue='Exited')
plt.title("Genre vs Churn")
plt.xlabel("Genre")
plt.ylabel("Nombre de clients")
plt.show()

# Taux de churn par genre
churn_by_gender = df.groupby('Gender')['Exited'].mean()
print(churn_by_gender)


# 2. Gender vs Exited
# Observation :
# 
# La proportion de clients hommes et femmes est √©quilibr√©e.
# 
# Le taux de churn est l√©g√®rement plus √©lev√© chez les femmes.
# 
# Interpr√©tation :
# 
# Le genre a un impact mod√©r√© mais existant.
# 
# Ce n‚Äôest pas une variable d√©cisive seule, mais elle peut aider combin√©e √† d‚Äôautres.
# 
# ***√Ä garder dans le mod√®le, mais ne pas s‚Äôattendre √† une importance tr√®s forte.

# In[9]:


plt.figure(figsize=(6, 4))
sns.countplot(data=df, x='Geography', hue='Exited')
plt.title("Pays vs Churn")
plt.xlabel("Pays")
plt.ylabel("Nombre de clients")
plt.show()

# Taux de churn par pays
churn_by_country = df.groupby('Geography')['Exited'].mean()
print(churn_by_country)


# 3. Geography vs Exited
# Observation :
# 
# Les clients allemands ont un taux de churn nettement plus √©lev√©.
# 
# Les clients espagnols et fran√ßais quittent beaucoup moins la banque.
# 
# Interpr√©tation :
# 
# La localisation g√©ographique est tr√®s importante pour pr√©dire le churn.
# 
# Il se peut que l‚Äôoffre bancaire soit moins attractive ou le service client moins bon en Allemagne.
# 
# *** √Ä garder absolument, tr√®s bonne variable explicative.

# In[18]:


plt.figure(figsize=(10, 5))
sns.histplot(data=df, x='Balance', hue='Exited', bins=40, kde=True, multiple='stack')
plt.title("Solde (Balance) vs Churn")
plt.xlabel("Solde")
plt.ylabel("Nombre de clients")
plt.show()


# 4. Balance vs Exited
# Observation :
# 
# Il y a deux groupes tr√®s visibles : ceux avec balance = 0 et ceux avec un solde √©lev√©.
# 
# Le churn est plus √©lev√© dans les balances moyennes √† √©lev√©es.
# 
# Interpr√©tation :
# 
# √âtonnamment, les clients avec 0 de solde partent peu.
# 
# Peut-√™tre des comptes inactifs ou des comptes secondaires ?
# 
# Les clients avec plus d‚Äôargent sont plus √† risque de partir (peut-√™tre courtis√©s par la concurrence ?)
# 
# **** Variable utile, mais √† interpr√©ter finement.

# In[10]:


sns.countplot(data=df, x='NumOfProducts', hue='Exited')
plt.title("Nombre de produits vs Churn")
plt.xlabel("Nombre de produits bancaires")
plt.ylabel("Nombre de clients")
plt.show()


# 5. NumOfProducts vs Exited
# Observation :
# 
# Les clients ayant 1 produit sont les plus nombreux.
# 
# Les clients ayant 3 produits ou plus sont tr√®s rares, mais leur churn est √©lev√©.
# 
# Les clients avec 4 produits ont un taux de churn extr√™mement √©lev√©.
# 
# Interpr√©tation :
# 
# L‚Äôusage de plusieurs produits ne garantit pas la fid√©lit√©.
# 
# Un churn massif √† 4 produits peut indiquer un segment √† probl√®me (VIP insatisfaits ? offres mal adapt√©es ?).
# 
# **** Tr√®s bon indicateur √† inclure.
# 
# 

# In[11]:


plt.figure(figsize=(10, 5))
sns.histplot(data=df, x='EstimatedSalary', hue='Exited', bins=40, kde=True, multiple='stack')
plt.title("Salaire estim√© vs Churn")
plt.xlabel("Salaire")
plt.ylabel("Nombre de clients")
plt.show()


# EstimatedSalary vs Exited
# Observation :
# 
# La distribution est assez uniforme (salaire g√©n√©r√© al√©atoirement).
# 
# Le churn n‚Äôaugmente pas clairement avec le salaire.
# 
# Interpr√©tation :
# 
# Le salaire estim√© n‚Äôest pas discriminant ici.
# 
# Peu corr√©l√© √† la probabilit√© de partir.
# 
# ‚ö†Ô∏è √Ä tester en mod√©lisation, mais probablement faible importance

# In[22]:


# Matrice de corr√©lation (num√©rique seulement)
plt.figure(figsize=(12, 8))
sns.heatmap(df.corr(numeric_only=True), annot=True, cmap="coolwarm", fmt=".2f")
plt.title("Corr√©lation entre variables num√©riques")
plt.show()


# Observation :
# 
# Age est positivement corr√©l√© √† Exited.
# 
# NumOfProducts a une corr√©lation n√©gative.
# 
# CreditScore ou EstimatedSalary ont peu de corr√©lation directe.
# 
# Interpr√©tation :
# 
# Certaines variables (comme Age) sont plus li√©es √† la cible.
# 
# D‚Äôautres (comme CreditScore) peuvent jouer un r√¥le en interaction avec d‚Äôautres variables.
# 
# 

# In[12]:


# encodage 

#Gender ‚Üí encodage binaire
df['Gender'] = df['Gender'].map({'Male': 0, 'Female': 1})


# In[13]:


#Geography ‚Üí encodage One-Hot
df = pd.get_dummies(df, columns=['Geography'], drop_first=True)


# Standardisation des variables num√©riques

# In[14]:


from sklearn.preprocessing import StandardScaler

# On ne standardise pas la variable cible 'Exited'
features_to_scale = ['CreditScore', 'Age', 'Tenure', 'Balance', 
                     'NumOfProducts', 'EstimatedSalary']

scaler = StandardScaler()
df[features_to_scale] = scaler.fit_transform(df[features_to_scale])


# S√©paration des features et de la target
# 

# In[15]:


X = df.drop('Exited', axis=1)
y = df['Exited']


# Split train/test

# In[16]:


from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)


# Entrainement du mod√®le : Regression Logistic

# In[17]:


from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score

# Initialisation du mod√®le (avec class_weight='balanced' pour g√©rer le d√©s√©quilibre)
model = LogisticRegression(max_iter=1000, class_weight='balanced', random_state=42)

# Entra√Ænement
model.fit(X_train, y_train)

# Pr√©diction sur test
y_pred = model.predict(X_test)
y_pred_proba = model.predict_proba(X_test)[:, 1]

# √âvaluation
print("Classification Report:\n", classification_report(y_test, y_pred))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))
print("AUC-ROC:", roc_auc_score(y_test, y_pred_proba))


# Precision (Pr√©cision) : parmi les clients pr√©dits comme churners (classe 1), combien le sont vraiment ?
# 
# Classe 1 : 39% ‚Üí Peu √©lev√©e, beaucoup de faux positifs.
# 
# Recall (Rappel ou Sensibilit√©) : parmi les clients qui ont r√©ellement churn√©, combien ont √©t√© correctement d√©tect√©s ?
# 
# Classe 1 : 70% ‚Üí Bon rappel, tu d√©tectes 70% des churners.
# 
# F1-score : compromis entre pr√©cision et rappel.
# 
# Classe 1 : 0.50 ‚Üí Moyenne basse, signal que le mod√®le a du mal √† bien √©quilibrer pr√©cision et rappel sur les churners.
# 
# Support : nombre d‚Äô√©chantillons par classe dans le test (1593 rest√©s, 407 partis).
# 
# 

# Il d√©tecte 70% des clients qui vont partir (rappel correct).
# 
# Il diff√©rencie bien les clients ‚Äúrest√©s‚Äù vs ‚Äúpartis‚Äù avec un AUC de 0.78.
# 
# La pr√©cision globale de 71% montre que le mod√®le n‚Äôest pas ‚Äúau hasard‚Äù.
 
 

 #Je  peux pr√©dire le churn avec une performance correcte.

#Mais je dois encore am√©liorer le mod√®le ou adapter ta strat√©gie selon ce que la banque pr√©f√®re :

#Maximiser la d√©tection des churners (favoriser le rappel)

#Minimiser les fausses alertes (favoriser la pr√©cision)
# # Le mod√®le actuel permet d‚Äôanticiper environ 70% des d√©parts clients, mais g√©n√®re aussi un nombre non n√©gligeable de fausses alertes. Il constitue une bonne base pour affiner la strat√©gie de fid√©lisation, en ajustant le seuil de d√©tection ou en int√©grant des donn√©es suppl√©mentaires pour am√©liorer la pr√©cision.

# Je vais essayer d'autres mod√®les 

# In[18]:


from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score

# Initialisation du mod√®le
rf_model = RandomForestClassifier(
    n_estimators=100,      # nombre d'arbres
    random_state=42,
    class_weight='balanced'  # pour g√©rer le d√©s√©quilibre
)
print("‚û°Ô∏è D√©but entra√Ænement Random Forest")

# Entra√Ænement
rf_model.fit(X_train, y_train)

# Pr√©diction
y_pred_rf = rf_model.predict(X_test)
y_pred_proba_rf = rf_model.predict_proba(X_test)[:, 1]

# √âvaluation
print("Classification Report Random Forest:\n", classification_report(y_test, y_pred_rf))
print("Confusion Matrix Random Forest:\n", confusion_matrix(y_test, y_pred_rf))
print("AUC-ROC Random Forest:", roc_auc_score(y_test, y_pred_proba_rf))


# Pr√©cision pour churners (1) : 78%, beaucoup mieux que la r√©gression logistique.
# 
# Rappel pour churners (1) : 46%, plus faible qu'avant (r√©gression logistique avait 70%).
# 
# F1-score plus √©lev√© (0.58 vs 0.50), globalement meilleure performance sur la classe 1.
# 
# 2. Accuracy et AUC
# Accuracy = 86% (vs 71% LR) ‚Üí grosse am√©lioration globale.
# 
# AUC-ROC = 0.85 (vs 0.78 LR) ‚Üí meilleure capacit√© √† distinguer churn/non-churn.
# 
#Interpr√©tation: 

#Le Random Forest r√©duit drastiquement les fausses alertes ‚Üí mieux pour ne pas gaspiller les ressources sur des clients fid√®les.

#En revanche, il attrape moins de churners (rappel plus faible), donc il y a un compromis.

#Selon la strat√©gie de la banque (pr√©venir √† tout prix ou √©viter les faux positifs), tu peux choisir entre le mod√®le ou ajuster le seuil
# Ce que montre le mod√®le Random Forest :
# Le mod√®le est capable de bien rep√©rer les clients qui vont rester : il les identifie correctement presque 97 fois sur 100 (tr√®s fiable).
# 
# Pour les clients qui risquent de partir, le mod√®le est plus prudent :
# 
# Quand il dit qu‚Äôun client va partir, il a raison 78% du temps (c‚Äôest fiable).
# 
# Mais il ne d√©tecte que 46% des clients qui vont r√©ellement partir (il en manque un peu plus de la moiti√©).
# 
# 
#Que cela signifie pour la banque ?
#La banque ne va pas trop gaspiller d'efforts √† courir apr√®s des clients qui ne partiront pas (peu de fausses alertes).

#Par contre, beaucoup de clients √† risque de d√©part ne seront pas d√©tect√©s, donc la banque pourrait manquer des occasions de les retenir.
# Solution : essayer d'ajuster le mod√®le 
#     
#     Pour d√©tecter plus de clients √† risque (augmenter le rappel), on peut ajuster le seuil de d√©cision du mod√®le Random Forest.
# 
# Explication rapide :
# Par d√©faut, un mod√®le classe un client en ‚Äúpartant‚Äù si la probabilit√© pr√©dite est ‚â• 0.5.
# Si on baisse ce seuil (par exemple √† 0.3), le mod√®le devient plus ‚Äúsensible‚Äù : il va pr√©dire ‚Äúpartant‚Äù plus facilement, donc attraper plus de churners, mais aussi g√©n√©rer plus de fausses alertes.
# 
# 

# In[19]:


import numpy as np
from sklearn.metrics import classification_report, confusion_matrix

# Pr√©dire les probabilit√©s pour la classe "1" (partant)
y_proba = rf_model.predict_proba(X_test)[:, 1]

# Choisir un seuil plus bas, par exemple 0.3 au lieu de 0.5
threshold = 0.3
y_pred_adjusted = (y_proba >= threshold).astype(int)

# √âvaluer les performances avec ce nouveau seuil
print("Classification Report avec seuil =", threshold)
print(classification_report(y_test, y_pred_adjusted))

print("Matrice de confusion avec seuil =", threshold)
print(confusion_matrix(y_test, y_pred_adjusted))


# Ce que j'ai am√©lior√© en baissant le seuil √† 0.3 :
# Je d√©tecte maintenant 65 % des clients qui vont r√©ellement partir (contre 46 % avant).
# 
# mon mod√®le est plus sensible aux clients √† risque, ce qui est exactement ce que je cherchais.
# 
# L‚Äôaccuracy globale reste bonne : 83 %.

# # üß† Conclusion :
# Mon mod√®le est maintenant plus utile pour anticiper les d√©parts de clients, ce qui correspond exactement √† mon objectif.
# 
# üìå Ce mod√®le peut maintenant √™tre utilis√© comme outil d‚Äôaide √† la d√©cision marketing : cibler les 264 clients identifi√©s √† risque pour les relancer, leur proposer des offres, etc.
# 
# 
import pickle

with open('random_forest_churn.pkl', 'wb') as f:
    pickle.dump(rf_model, f)
print("‚û°Ô∏è Pr√™t √† sauvegarder le mod√®le")

with open('scaler.pkl', 'wb') as f:
    pickle.dump(scaler, f)

print("‚úÖ Mod√®le et scaler sauvegard√©s avec succ√®s.")
