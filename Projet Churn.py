#!/usr/bin/env python
# coding: utf-8

# # I.Contexte et Objectif

# PrÃ©dire le dÃ©part des clients d'une banque Ã  partir de leurs donnÃ©es personnelles et comportementales. Ce modÃ¨le permettra Ã  la banque dâ€™anticiper les risques dâ€™attrition et de cibler les actions de fidÃ©lisation.

# # II. ProblÃ©matique

# - Quels facteurs influencent le dÃ©part des clients ?
# 
# - Peut-on prÃ©dire Ã  lâ€™avance si un client va quitter la banque ?
# 
# 

# # III. Analyse exploratoire (EDA)

# In[1]:


#import fichier

import pandas as pd 

df = pd.read_csv("C:\\Users\\Valencia\\Downloads\\Churn_Modelling (1).csv")

#aperÃ§u des 5 premiÃ¨res lignes 

df.head()


# In[2]:


# Dimensions du jeu de donnÃ©es
print(f"Nombre de lignes : {df.shape[0]}")
print(f"Nombre de colonnes : {df.shape[1]}")
 


# In[3]:


# Types de donnÃ©es et valeurs manquantes
df.info()


# Conclusion : Aucune valeur manquante dans mon Dataset

# In[4]:


df = df.drop(columns=["RowNumber", "CustomerId", "Surname"])


# In[5]:


# Analyse de la variable cible 

import seaborn as sns
import matplotlib.pyplot as plt

# RÃ©partition de la variable cible
sns.countplot(x="Exited", data=df)
plt.title("RÃ©partition des clients quittant la banque (Exited)")
plt.xlabel("Exited (0 = reste, 1 = quitte)")
plt.ylabel("Nombre de clients")
plt.show()


# In[6]:


# Pourcentage de churn
churn_rate = df['Exited'].mean()
print(f"Taux de churn : {churn_rate:.2%}")


#  Le taux de churn de 20,37% signifie que 20,37% des clients du dataset ont quittÃ© la banque, ce qui est une information clÃ© dans un projet de classification sur le churn

# ğŸ“Š InterprÃ©tation
# Sur 10 000 clients, environ 2 037 ont quittÃ© la banque (Exited = 1).
# 
# Les 79,63% restants, soit environ 7 963 clients, sont restÃ©s (Exited = 0).
# 
# Il sâ€™agit dâ€™un problÃ¨me de classification binaire dÃ©sÃ©quilibrÃ©, mais pas fortement (en gÃ©nÃ©ral, un dÃ©sÃ©quilibre commence Ã  poser problÃ¨me en dessous de 10â€“15%).

# # Analyse univariÃ©e + bivariÃ©e (relation avec Exited)
# 

# In[7]:


# Distribution de l'Ã¢ge selon le churn
plt.figure(figsize=(10, 5))
sns.histplot(data=df, x='Age', hue='Exited', bins=30, kde=True, multiple="stack")
plt.title("RÃ©partition de l'Ã¢ge selon le churn")
plt.xlabel("Ã‚ge")
plt.ylabel("Nombre de clients")
plt.show()


# ğŸ“Š 1. Age vs Exited
# Observation :
# 
# Les clients entre 30 et 40 ans sont majoritaires.
# 
# Le taux de churn augmente significativement avec lâ€™Ã¢ge, notamment aprÃ¨s 45 ans.
# 
# Les plus jeunes clients partent peu.
# 
# InterprÃ©tation :
# 
# Lâ€™Ã¢ge est un facteur discriminant fort.
# 
# Les clients plus Ã¢gÃ©s sont peut-Ãªtre plus exigeants ou plus susceptibles de quitter la banque.
# 
# *** Pertinent Ã  garder pour la modÃ©lisation.
# 
# 

# In[8]:


# RÃ©partition des sexes par churn
plt.figure(figsize=(6, 4))
sns.countplot(data=df, x='Gender', hue='Exited')
plt.title("Genre vs Churn")
plt.xlabel("Genre")
plt.ylabel("Nombre de clients")
plt.show()

# Taux de churn par genre
churn_by_gender = df.groupby('Gender')['Exited'].mean()
print(churn_by_gender)


# 2. Gender vs Exited
# Observation :
# 
# La proportion de clients hommes et femmes est Ã©quilibrÃ©e.
# 
# Le taux de churn est lÃ©gÃ¨rement plus Ã©levÃ© chez les femmes.
# 
# InterprÃ©tation :
# 
# Le genre a un impact modÃ©rÃ© mais existant.
# 
# Ce nâ€™est pas une variable dÃ©cisive seule, mais elle peut aider combinÃ©e Ã  dâ€™autres.
# 
# ***Ã€ garder dans le modÃ¨le, mais ne pas sâ€™attendre Ã  une importance trÃ¨s forte.

# In[9]:


plt.figure(figsize=(6, 4))
sns.countplot(data=df, x='Geography', hue='Exited')
plt.title("Pays vs Churn")
plt.xlabel("Pays")
plt.ylabel("Nombre de clients")
plt.show()

# Taux de churn par pays
churn_by_country = df.groupby('Geography')['Exited'].mean()
print(churn_by_country)


# 3. Geography vs Exited
# Observation :
# 
# Les clients allemands ont un taux de churn nettement plus Ã©levÃ©.
# 
# Les clients espagnols et franÃ§ais quittent beaucoup moins la banque.
# 
# InterprÃ©tation :
# 
# La localisation gÃ©ographique est trÃ¨s importante pour prÃ©dire le churn.
# 
# Il se peut que lâ€™offre bancaire soit moins attractive ou le service client moins bon en Allemagne.
# 
# *** Ã€ garder absolument, trÃ¨s bonne variable explicative.

# In[18]:


plt.figure(figsize=(10, 5))
sns.histplot(data=df, x='Balance', hue='Exited', bins=40, kde=True, multiple='stack')
plt.title("Solde (Balance) vs Churn")
plt.xlabel("Solde")
plt.ylabel("Nombre de clients")
plt.show()


# 4. Balance vs Exited
# Observation :
# 
# Il y a deux groupes trÃ¨s visibles : ceux avec balance = 0 et ceux avec un solde Ã©levÃ©.
# 
# Le churn est plus Ã©levÃ© dans les balances moyennes Ã  Ã©levÃ©es.
# 
# InterprÃ©tation :
# 
# Ã‰tonnamment, les clients avec 0 de solde partent peu.
# 
# Peut-Ãªtre des comptes inactifs ou des comptes secondaires ?
# 
# Les clients avec plus dâ€™argent sont plus Ã  risque de partir (peut-Ãªtre courtisÃ©s par la concurrence ?)
# 
# **** Variable utile, mais Ã  interprÃ©ter finement.

# In[10]:


sns.countplot(data=df, x='NumOfProducts', hue='Exited')
plt.title("Nombre de produits vs Churn")
plt.xlabel("Nombre de produits bancaires")
plt.ylabel("Nombre de clients")
plt.show()


# 5. NumOfProducts vs Exited
# Observation :
# 
# Les clients ayant 1 produit sont les plus nombreux.
# 
# Les clients ayant 3 produits ou plus sont trÃ¨s rares, mais leur churn est Ã©levÃ©.
# 
# Les clients avec 4 produits ont un taux de churn extrÃªmement Ã©levÃ©.
# 
# InterprÃ©tation :
# 
# Lâ€™usage de plusieurs produits ne garantit pas la fidÃ©litÃ©.
# 
# Un churn massif Ã  4 produits peut indiquer un segment Ã  problÃ¨me (VIP insatisfaits ? offres mal adaptÃ©es ?).
# 
# **** TrÃ¨s bon indicateur Ã  inclure.
# 
# 

# In[11]:


plt.figure(figsize=(10, 5))
sns.histplot(data=df, x='EstimatedSalary', hue='Exited', bins=40, kde=True, multiple='stack')
plt.title("Salaire estimÃ© vs Churn")
plt.xlabel("Salaire")
plt.ylabel("Nombre de clients")
plt.show()


# EstimatedSalary vs Exited
# Observation :
# 
# La distribution est assez uniforme (salaire gÃ©nÃ©rÃ© alÃ©atoirement).
# 
# Le churn nâ€™augmente pas clairement avec le salaire.
# 
# InterprÃ©tation :
# 
# Le salaire estimÃ© nâ€™est pas discriminant ici.
# 
# Peu corrÃ©lÃ© Ã  la probabilitÃ© de partir.
# 
# âš ï¸ Ã€ tester en modÃ©lisation, mais probablement faible importance

# In[22]:


# Matrice de corrÃ©lation (numÃ©rique seulement)
plt.figure(figsize=(12, 8))
sns.heatmap(df.corr(numeric_only=True), annot=True, cmap="coolwarm", fmt=".2f")
plt.title("CorrÃ©lation entre variables numÃ©riques")
plt.show()


# Observation :
# 
# Age est positivement corrÃ©lÃ© Ã  Exited.
# 
# NumOfProducts a une corrÃ©lation nÃ©gative.
# 
# CreditScore ou EstimatedSalary ont peu de corrÃ©lation directe.
# 
# InterprÃ©tation :
# 
# Certaines variables (comme Age) sont plus liÃ©es Ã  la cible.
# 
# Dâ€™autres (comme CreditScore) peuvent jouer un rÃ´le en interaction avec dâ€™autres variables.
# 
# 

# In[12]:


# encodage 

#Gender â†’ encodage binaire
df['Gender'] = df['Gender'].map({'Male': 0, 'Female': 1})


# In[13]:


#Geography â†’ encodage One-Hot
df = pd.get_dummies(df, columns=['Geography'], drop_first=True)


# Standardisation des variables numÃ©riques

# In[14]:


from sklearn.preprocessing import StandardScaler

# On ne standardise pas la variable cible 'Exited'
features_to_scale = ['CreditScore', 'Age', 'Tenure', 'Balance', 
                     'NumOfProducts', 'EstimatedSalary']

scaler = StandardScaler()
df[features_to_scale] = scaler.fit_transform(df[features_to_scale])


# SÃ©paration des features et de la target
# 

# In[15]:


X = df.drop('Exited', axis=1)
y = df['Exited']


# Split train/test

# In[16]:


from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)


# Entrainement du modÃ¨le : Regression Logistic

# In[17]:


from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score

# Initialisation du modÃ¨le (avec class_weight='balanced' pour gÃ©rer le dÃ©sÃ©quilibre)
model = LogisticRegression(max_iter=1000, class_weight='balanced', random_state=42)

# EntraÃ®nement
model.fit(X_train, y_train)

# PrÃ©diction sur test
y_pred = model.predict(X_test)
y_pred_proba = model.predict_proba(X_test)[:, 1]

# Ã‰valuation
print("Classification Report:\n", classification_report(y_test, y_pred))
print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred))
print("AUC-ROC:", roc_auc_score(y_test, y_pred_proba))


# Precision (PrÃ©cision) : parmi les clients prÃ©dits comme churners (classe 1), combien le sont vraiment ?
# 
# Classe 1 : 39% â†’ Peu Ã©levÃ©e, beaucoup de faux positifs.
# 
# Recall (Rappel ou SensibilitÃ©) : parmi les clients qui ont rÃ©ellement churnÃ©, combien ont Ã©tÃ© correctement dÃ©tectÃ©s ?
# 
# Classe 1 : 70% â†’ Bon rappel, tu dÃ©tectes 70% des churners.
# 
# F1-score : compromis entre prÃ©cision et rappel.
# 
# Classe 1 : 0.50 â†’ Moyenne basse, signal que le modÃ¨le a du mal Ã  bien Ã©quilibrer prÃ©cision et rappel sur les churners.
# 
# Support : nombre dâ€™Ã©chantillons par classe dans le test (1593 restÃ©s, 407 partis).
# 
# 

# Il dÃ©tecte 70% des clients qui vont partir (rappel correct).
# 
# Il diffÃ©rencie bien les clients â€œrestÃ©sâ€ vs â€œpartisâ€ avec un AUC de 0.78.
# 
# La prÃ©cision globale de 71% montre que le modÃ¨le nâ€™est pas â€œau hasardâ€.
 
 

 #Je  peux prÃ©dire le churn avec une performance correcte.

#Mais je dois encore amÃ©liorer le modÃ¨le ou adapter ta stratÃ©gie selon ce que la banque prÃ©fÃ¨re :

#Maximiser la dÃ©tection des churners (favoriser le rappel)

#Minimiser les fausses alertes (favoriser la prÃ©cision)
# # Le modÃ¨le actuel permet dâ€™anticiper environ 70% des dÃ©parts clients, mais gÃ©nÃ¨re aussi un nombre non nÃ©gligeable de fausses alertes. Il constitue une bonne base pour affiner la stratÃ©gie de fidÃ©lisation, en ajustant le seuil de dÃ©tection ou en intÃ©grant des donnÃ©es supplÃ©mentaires pour amÃ©liorer la prÃ©cision.

# Je vais essayer d'autres modÃ¨les 

# In[18]:


from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score

# Initialisation du modÃ¨le
rf_model = RandomForestClassifier(
    n_estimators=100,      # nombre d'arbres
    random_state=42,
    class_weight='balanced'  # pour gÃ©rer le dÃ©sÃ©quilibre
)
print("â¡ï¸ DÃ©but entraÃ®nement Random Forest")

# EntraÃ®nement
rf_model.fit(X_train, y_train)

# PrÃ©diction
y_pred_rf = rf_model.predict(X_test)
y_pred_proba_rf = rf_model.predict_proba(X_test)[:, 1]

# Ã‰valuation
print("Classification Report Random Forest:\n", classification_report(y_test, y_pred_rf))
print("Confusion Matrix Random Forest:\n", confusion_matrix(y_test, y_pred_rf))
print("AUC-ROC Random Forest:", roc_auc_score(y_test, y_pred_proba_rf))


# PrÃ©cision pour churners (1) : 78%, beaucoup mieux que la rÃ©gression logistique.
# 
# Rappel pour churners (1) : 46%, plus faible qu'avant (rÃ©gression logistique avait 70%).
# 
# F1-score plus Ã©levÃ© (0.58 vs 0.50), globalement meilleure performance sur la classe 1.
# 
# 2. Accuracy et AUC
# Accuracy = 86% (vs 71% LR) â†’ grosse amÃ©lioration globale.
# 
# AUC-ROC = 0.85 (vs 0.78 LR) â†’ meilleure capacitÃ© Ã  distinguer churn/non-churn.
# 
#InterprÃ©tation: 

#Le Random Forest rÃ©duit drastiquement les fausses alertes â†’ mieux pour ne pas gaspiller les ressources sur des clients fidÃ¨les.

#En revanche, il attrape moins de churners (rappel plus faible), donc il y a un compromis.

#Selon la stratÃ©gie de la banque (prÃ©venir Ã  tout prix ou Ã©viter les faux positifs), tu peux choisir entre le modÃ¨le ou ajuster le seuil
# Ce que montre le modÃ¨le Random Forest :
# Le modÃ¨le est capable de bien repÃ©rer les clients qui vont rester : il les identifie correctement presque 97 fois sur 100 (trÃ¨s fiable).
# 
# Pour les clients qui risquent de partir, le modÃ¨le est plus prudent :
# 
# Quand il dit quâ€™un client va partir, il a raison 78% du temps (câ€™est fiable).
# 
# Mais il ne dÃ©tecte que 46% des clients qui vont rÃ©ellement partir (il en manque un peu plus de la moitiÃ©).
# 
# 
#Que cela signifie pour la banque ?
#La banque ne va pas trop gaspiller d'efforts Ã  courir aprÃ¨s des clients qui ne partiront pas (peu de fausses alertes).

#Par contre, beaucoup de clients Ã  risque de dÃ©part ne seront pas dÃ©tectÃ©s, donc la banque pourrait manquer des occasions de les retenir.
# Solution : essayer d'ajuster le modÃ¨le 
#     
#     Pour dÃ©tecter plus de clients Ã  risque (augmenter le rappel), on peut ajuster le seuil de dÃ©cision du modÃ¨le Random Forest.
# 
# Explication rapide :
# Par dÃ©faut, un modÃ¨le classe un client en â€œpartantâ€ si la probabilitÃ© prÃ©dite est â‰¥ 0.5.
# Si on baisse ce seuil (par exemple Ã  0.3), le modÃ¨le devient plus â€œsensibleâ€ : il va prÃ©dire â€œpartantâ€ plus facilement, donc attraper plus de churners, mais aussi gÃ©nÃ©rer plus de fausses alertes.
# 
# 

# In[19]:


import numpy as np
from sklearn.metrics import classification_report, confusion_matrix

# PrÃ©dire les probabilitÃ©s pour la classe "1" (partant)
y_proba = rf_model.predict_proba(X_test)[:, 1]

# Choisir un seuil plus bas, par exemple 0.3 au lieu de 0.5
threshold = 0.3
y_pred_adjusted = (y_proba >= threshold).astype(int)

# Ã‰valuer les performances avec ce nouveau seuil
print("Classification Report avec seuil =", threshold)
print(classification_report(y_test, y_pred_adjusted))

print("Matrice de confusion avec seuil =", threshold)
print(confusion_matrix(y_test, y_pred_adjusted))


# Ce que j'ai amÃ©liorÃ© en baissant le seuil Ã  0.3 :
# Je dÃ©tecte maintenant 65 % des clients qui vont rÃ©ellement partir (contre 46 % avant).
# 
# mon modÃ¨le est plus sensible aux clients Ã  risque, ce qui est exactement ce que je cherchais.
# 
# Lâ€™accuracy globale reste bonne : 83 %.

# # ğŸ§  Conclusion :
# Mon modÃ¨le est maintenant plus utile pour anticiper les dÃ©parts de clients, ce qui correspond exactement Ã  mon objectif.
# 
# ğŸ“Œ Ce modÃ¨le peut maintenant Ãªtre utilisÃ© comme outil dâ€™aide Ã  la dÃ©cision marketing : cibler les 264 clients identifiÃ©s Ã  risque pour les relancer, leur proposer des offres, etc.
# 
# 
import pickle

with open('random_forest_churn.pkl', 'wb') as f:
    pickle.dump(rf_model, f)
print("â¡ï¸ PrÃªt Ã  sauvegarder le modÃ¨le")

with open('scaler.pkl', 'wb') as f:
    pickle.dump(scaler, f)

print("âœ… ModÃ¨le et scaler sauvegardÃ©s avec succÃ¨s.")
